{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'E:\\NB\\Machine Learning\\UOM - DataCrunch\\RoboZen404_DataCrunch\\dataset\\train.csv') #replace with your file name.\n",
    "test_df = pd.read_csv(r'E:\\NB\\Machine Learning\\UOM - DataCrunch\\RoboZen404_DataCrunch\\dataset\\test.csv')\n",
    "\n",
    "# Load your train and test datasets\n",
    "train_df['is_test'] = 0  # Mark training data\n",
    "test_df['is_test'] = 1   # Mark test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84960, 18)\n",
      "   ID  Year  Month  Day   kingdom   latitude  longitude  Avg_Temperature  \\\n",
      "0   1     1      4    1   Arcadia  24.280002 -37.229980            25.50   \n",
      "1   2     1      4    1  Atlantis  22.979999 -37.329990           299.65   \n",
      "2   3     1      4    1    Avalon  22.880000 -37.130006            26.30   \n",
      "3   4     1      4    1   Camelot  24.180003 -36.929994            24.00   \n",
      "4   5     1      4    1     Dorne  25.780002 -37.530000            28.00   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                       30.50                8.5   \n",
      "1                      305.15                5.9   \n",
      "2                       31.50                5.2   \n",
      "3                       28.40                8.2   \n",
      "4                       32.80                5.7   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                          10.3      22.52        58.89             16   \n",
      "1                           8.2      22.73        11.83             12   \n",
      "2                           6.4      22.73        11.83             12   \n",
      "3                          10.7      22.67        75.27             16   \n",
      "4                          10.2      22.35         4.81              8   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  is_test  \n",
      "0         8.6             283            1.648659        0  \n",
      "1        15.8             161            1.583094        0  \n",
      "2        15.8             161            1.593309        0  \n",
      "3         6.4             346            1.638997        0  \n",
      "4        16.7             185            1.719189        0  \n",
      "(4530, 18)\n",
      "      ID  Year  Month  Day   kingdom  is_test  latitude  longitude  \\\n",
      "0  84961     9      1    1   Arcadia        1       NaN        NaN   \n",
      "1  84962     9      1    1  Atlantis        1       NaN        NaN   \n",
      "2  84963     9      1    1    Avalon        1       NaN        NaN   \n",
      "3  84964     9      1    1   Camelot        1       NaN        NaN   \n",
      "4  84965     9      1    1     Dorne        1       NaN        NaN   \n",
      "\n",
      "   Avg_Temperature  Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0              NaN                         NaN                NaN   \n",
      "1              NaN                         NaN                NaN   \n",
      "2              NaN                         NaN                NaN   \n",
      "3              NaN                         NaN                NaN   \n",
      "4              NaN                         NaN                NaN   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                           NaN        NaN          NaN            NaN   \n",
      "1                           NaN        NaN          NaN            NaN   \n",
      "2                           NaN        NaN          NaN            NaN   \n",
      "3                           NaN        NaN          NaN            NaN   \n",
      "4                           NaN        NaN          NaN            NaN   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  \n",
      "0         NaN             NaN                 NaN  \n",
      "1         NaN             NaN                 NaN  \n",
      "2         NaN             NaN                 NaN  \n",
      "3         NaN             NaN                 NaN  \n",
      "4         NaN             NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# List of missing columns in test data\n",
    "missing_cols = ['latitude', 'longitude', 'Avg_Temperature', 'Avg_Feels_Like_Temperature', \n",
    "                'Temperature_Range', 'Feels_Like_Temperature_Range', 'Radiation', \n",
    "                'Rain_Amount', 'Rain_Duration', 'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']\n",
    "\n",
    "# Add them with NaN values in test data\n",
    "for col in missing_cols:\n",
    "    test_df[col] = np.nan\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                              0\n",
      "Year                            0\n",
      "Month                           0\n",
      "Day                             0\n",
      "kingdom                         0\n",
      "latitude                        0\n",
      "longitude                       0\n",
      "Avg_Temperature                 0\n",
      "Avg_Feels_Like_Temperature      0\n",
      "Temperature_Range               0\n",
      "Feels_Like_Temperature_Range    0\n",
      "Radiation                       0\n",
      "Rain_Amount                     0\n",
      "Rain_Duration                   0\n",
      "Wind_Speed                      0\n",
      "Wind_Direction                  0\n",
      "Evapotranspiration              0\n",
      "is_test                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no any missing values in the train dataset. So we can concatinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data\n",
    "full_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           latitude     longitude  Avg_Feels_Like_Temperature  \\\n",
      "count  8.496000e+04  8.496000e+04                8.496000e+04   \n",
      "mean   1.784992e-15 -1.646687e-14               -8.346535e-17   \n",
      "std    1.000006e+00  1.000006e+00                1.000006e+00   \n",
      "min   -1.406599e+00 -9.477272e-01               -9.036781e-01   \n",
      "25%   -4.048639e-01 -7.432270e-01               -8.170698e-01   \n",
      "50%   -2.796493e-01 -5.386612e-01               -8.006441e-01   \n",
      "75%    3.464329e-01  2.795403e-01                1.225318e+00   \n",
      "max    3.226416e+00  3.143342e+00                1.268622e+00   \n",
      "\n",
      "       Temperature_Range  Feels_Like_Temperature_Range  Rain_Duration  \\\n",
      "count       8.496000e+04                  8.496000e+04   8.496000e+04   \n",
      "mean        1.552221e-16                  9.634478e-17   9.366853e-17   \n",
      "std         1.000006e+00                  1.000006e+00   1.000006e+00   \n",
      "min        -2.449927e+00                 -2.344662e+00  -1.230131e+00   \n",
      "25%        -7.813450e-01                 -7.847088e-01  -9.535631e-01   \n",
      "50%        -1.240248e-01                 -6.797353e-02  -1.238584e-01   \n",
      "75%         5.838585e-01                  6.909227e-01   8.441305e-01   \n",
      "max         5.083974e+00                  4.611886e+00   2.088688e+00   \n",
      "\n",
      "       Evapotranspiration  \n",
      "count        8.496000e+04  \n",
      "mean         1.578984e-16  \n",
      "std          1.000006e+00  \n",
      "min         -5.200972e+00  \n",
      "25%         -5.326730e-01  \n",
      "50%          9.329300e-02  \n",
      "75%          6.680502e-01  \n",
      "max          2.928921e+00  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define columns that should NOT be scaled (date-related + target variables)\n",
    "date_cols = ['Year', 'Month', 'Day', 'is_test', 'ID']\n",
    "target_cols = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
    "\n",
    "# Get only numerical features (excluding target variables and date columns)\n",
    "feature_cols = [col for col in full_df.select_dtypes(include=np.number).columns if col not in date_cols + target_cols]\n",
    "\n",
    "# Apply StandardScaler only to feature columns\n",
    "scaler = StandardScaler()\n",
    "full_df[feature_cols] = scaler.fit_transform(full_df[feature_cols])\n",
    "\n",
    "# Now, train the model as before without modifying the target variables\n",
    "print(full_df[feature_cols].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3  # Adjust based on need\n",
    "\n",
    "smooth_features = ['Avg_Temperature', 'Avg_Feels_Like_Temperature', \n",
    "                   'Temperature_Range', 'Feels_Like_Temperature_Range',\n",
    "                   'Radiation', 'Evapotranspiration']\n",
    "\n",
    "for feature in smooth_features:\n",
    "    full_df[feature] = full_df[feature].rolling(window=window_size, min_periods=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3  # Smoothing factor (0 < alpha < 1)\n",
    "\n",
    "for feature in smooth_features:\n",
    "    full_df[feature] = full_df[feature].ewm(alpha=alpha, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0   1     1      4    1   Arcadia  0.346433   0.075040        25.500000   \n",
      "1   2     1      4    1  Atlantis -1.281385  -0.129534        66.622500   \n",
      "2   3     1      4    1    Avalon -1.406599   0.279540        81.780750   \n",
      "3   4     1      4    1   Camelot  0.221218   0.688672        92.241525   \n",
      "4   5     1      4    1     Dorne  2.224680  -0.538661        72.399067   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                   -0.815577           1.595120   \n",
      "1                   -0.507987           1.397924   \n",
      "2                   -0.394457           1.158761   \n",
      "3                   -0.316554           0.976178   \n",
      "4                   -0.465365           0.838257   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                      1.660623  22.520000        58.89       0.982415   \n",
      "1                      1.527817  22.551500        11.83       0.429278   \n",
      "2                      1.314693  22.584050        11.83       0.429278   \n",
      "3                      1.182371  22.621835        75.27       0.982415   \n",
      "4                      1.174068  22.610284         4.81      -0.123858   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  is_test  \n",
      "0         8.6           283.0            0.363578        0  \n",
      "1        15.8           161.0            0.318846        0  \n",
      "2        15.8           161.0            0.277268        0  \n",
      "3         6.4           346.0            0.243769        0  \n",
      "4        16.7           185.0            0.282221        0  \n"
     ]
    }
   ],
   "source": [
    "# Check first few rows of full_df\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split full_df into train and test\n",
    "train_df = full_df[full_df['is_test'] == 0].drop(columns=['is_test'])\n",
    "test_df = full_df[full_df['is_test'] == 1].drop(columns=['is_test', 'Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction'])\n",
    "\n",
    "\n",
    "scaled_features = ['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range',\n",
    "                   'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount', 'Rain_Duration',\n",
    "                   'Wind_Speed', 'Evapotranspiration']\n",
    "\n",
    "\n",
    "scaled_features = [feature for feature in scaled_features if feature in full_df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84960, 17)\n",
      "   ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0   1     1      4    1   Arcadia  0.346433   0.075040        25.500000   \n",
      "1   2     1      4    1  Atlantis -1.281385  -0.129534        66.622500   \n",
      "2   3     1      4    1    Avalon -1.406599   0.279540        81.780750   \n",
      "3   4     1      4    1   Camelot  0.221218   0.688672        92.241525   \n",
      "4   5     1      4    1     Dorne  2.224680  -0.538661        72.399067   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                   -0.815577           1.595120   \n",
      "1                   -0.507987           1.397924   \n",
      "2                   -0.394457           1.158761   \n",
      "3                   -0.316554           0.976178   \n",
      "4                   -0.465365           0.838257   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                      1.660623  22.520000        58.89       0.982415   \n",
      "1                      1.527817  22.551500        11.83       0.429278   \n",
      "2                      1.314693  22.584050        11.83       0.429278   \n",
      "3                      1.182371  22.621835        75.27       0.982415   \n",
      "4                      1.174068  22.610284         4.81      -0.123858   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  \n",
      "0         8.6           283.0            0.363578  \n",
      "1        15.8           161.0            0.318846  \n",
      "2        15.8           161.0            0.277268  \n",
      "3         6.4           346.0            0.243769  \n",
      "4        16.7           185.0            0.282221  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after outlier removal: (0, 18)\n"
     ]
    }
   ],
   "source": [
    "z_threshold = 3  # Common threshold (|Z-score| > 3 is considered an outlier)\n",
    "full_df = full_df[(np.abs(zscore(full_df[scaled_features])) < z_threshold).all(axis=1)]\n",
    "\n",
    "print(\"Dataset shape after outlier removal:\", full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape after concatenation: (89490, 18)\n",
      "   ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0   1     1      4    1   Arcadia  0.346433   0.075040        25.500000   \n",
      "1   2     1      4    1  Atlantis -1.281385  -0.129534        66.622500   \n",
      "2   3     1      4    1    Avalon -1.406599   0.279540        81.780750   \n",
      "3   4     1      4    1   Camelot  0.221218   0.688672        92.241525   \n",
      "4   5     1      4    1     Dorne  2.224680  -0.538661        72.399067   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                   -0.815577           1.595120   \n",
      "1                   -0.507987           1.397924   \n",
      "2                   -0.394457           1.158761   \n",
      "3                   -0.316554           0.976178   \n",
      "4                   -0.465365           0.838257   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                      1.660623  22.520000        58.89       0.982415   \n",
      "1                      1.527817  22.551500        11.83       0.429278   \n",
      "2                      1.314693  22.584050        11.83       0.429278   \n",
      "3                      1.182371  22.621835        75.27       0.982415   \n",
      "4                      1.174068  22.610284         4.81      -0.123858   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  is_test  \n",
      "0         8.6           283.0            0.363578        0  \n",
      "1        15.8           161.0            0.318846        0  \n",
      "2        15.8           161.0            0.277268        0  \n",
      "3         6.4           346.0            0.243769        0  \n",
      "4        16.7           185.0            0.282221        0  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Concatenate the cleaned train_df and the test_df back into full_df\n",
    "# We add the 'is_test' column again for clarity, if you need it later\n",
    "train_df['is_test'] = 0  # Mark the train data\n",
    "test_df['is_test'] = 1   # Mark the test data\n",
    "\n",
    "# Concatenate train and test data back into full_df\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Step 3: Check the shape and preview of the concatenated data\n",
    "print(\"Full dataset shape after concatenation:\", full_df.shape)\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lag Features: We created lag features to capture temporal dependencies without relying on actual time. These included shifts of key variables like temperature, wind speed, and rain amount (e.g., 1-day lag).\n",
    "\n",
    "Rolling Features: We introduced rolling statistics, such as moving averages and rolling sums, to identify trends over a specified window (e.g., 7-day moving averages for temperature and rain).\n",
    "\n",
    "Seasonal Features: To account for cycles, we grouped the data into hypothetical seasons based on the \"Year\" variable, using a modulo operation to classify records into 4 seasons.\n",
    "\n",
    "Aggregated Features by Kingdom: We aggregated key variables like temperature and wind speed by \"kingdom\" to capture regional patterns and trends.\n",
    "\n",
    "External Variables: We considered adding external features like radiation levels or indicators based on thresholds (e.g., high radiation) to help the model capture important weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a lag of 1 day for 'Avg_Temperature'\n",
    "full_df['Avg_Temperature_Lag_1'] = full_df['Avg_Temperature'].shift(1)\n",
    "full_df['Wind_Speed_Lag_1'] = full_df['Wind_Speed'].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Avg_Temperature_Lag_2'] = full_df['Avg_Temperature'].shift(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average over 7 days for 'Avg_Temperature'\n",
    "full_df['Avg_Temperature_MA_7'] = full_df['Avg_Temperature'].rolling(window=7).mean()\n",
    "full_df['Rain_Amount_MA_7'] = full_df['Rain_Amount'].rolling(window=7).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling sum over 7 days\n",
    "full_df['Rain_Amount_Rolling_Sum_7'] = full_df['Rain_Amount'].rolling(window=7).sum()\n",
    "\n",
    "# Rolling standard deviation\n",
    "full_df['Wind_Speed_Rolling_Std_7'] = full_df['Wind_Speed'].rolling(window=7).std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal Features (Non-time-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Season'] = (full_df['Year'] % 4)  # Group into 4 seasons based on the hypothetical year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregated Features by Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Avg_Temperature_Kingdom_Mean'] = full_df.groupby('kingdom')['Avg_Temperature'].transform('mean')\n",
    "full_df['Wind_Speed_Kingdom_Mean'] = full_df.groupby('kingdom')['Wind_Speed'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['High_Radiation'] = (full_df['Radiation'] > full_df['Radiation'].median()).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "#result = adfuller(full_df['Avg_Temperature'])\n",
    "#print(f'ADF Statistic: {result[0]}')\n",
    "#print(f'p-value: {result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above values have tested ans since the ADF statistic is -31.50 and the p-value is 0.0, this means that the data is stationary. No need to do any transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SPLIT BACK INTO TRAIN AND TEST --- ###\n",
    "train_df = full_df[full_df['is_test'] == 0].drop(columns=['is_test'])\n",
    "test_df = full_df[full_df['is_test'] == 1].drop(columns=['is_test', 'Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84960, 28)\n",
      "   ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0   1     1      4    1   Arcadia  0.346433   0.075040        25.500000   \n",
      "1   2     1      4    1  Atlantis -1.281385  -0.129534        66.622500   \n",
      "2   3     1      4    1    Avalon -1.406599   0.279540        81.780750   \n",
      "3   4     1      4    1   Camelot  0.221218   0.688672        92.241525   \n",
      "4   5     1      4    1     Dorne  2.224680  -0.538661        72.399067   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  ...  Wind_Speed_Lag_1  \\\n",
      "0                   -0.815577           1.595120  ...               NaN   \n",
      "1                   -0.507987           1.397924  ...               8.6   \n",
      "2                   -0.394457           1.158761  ...              15.8   \n",
      "3                   -0.316554           0.976178  ...              15.8   \n",
      "4                   -0.465365           0.838257  ...               6.4   \n",
      "\n",
      "   Avg_Temperature_Lag_2  Avg_Temperature_MA_7  Rain_Amount_MA_7  \\\n",
      "0                    NaN                   NaN               NaN   \n",
      "1                    NaN                   NaN               NaN   \n",
      "2               25.50000                   NaN               NaN   \n",
      "3               66.62250                   NaN               NaN   \n",
      "4               81.78075                   NaN               NaN   \n",
      "\n",
      "   Rain_Amount_Rolling_Sum_7  Wind_Speed_Rolling_Std_7  Season  \\\n",
      "0                        NaN                       NaN       1   \n",
      "1                        NaN                       NaN       1   \n",
      "2                        NaN                       NaN       1   \n",
      "3                        NaN                       NaN       1   \n",
      "4                        NaN                       NaN       1   \n",
      "\n",
      "   Avg_Temperature_Kingdom_Mean  Wind_Speed_Kingdom_Mean  High_Radiation  \n",
      "0                    103.556554                14.891596               1  \n",
      "1                    107.467938                17.874894               1  \n",
      "2                    110.488605                17.874894               1  \n",
      "3                    112.398051                11.830049               1  \n",
      "4                     86.453685                24.203531               1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "\n",
    "# print(test_df.shape)\n",
    "# print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_21756\\2169461839.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  full_df['ds'] = pd.to_datetime(full_df['Year'].astype(str) + '-' + full_df['Month'].astype(str) + '-' + full_df['Day'].astype(str))\n",
      "22:55:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:56:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Prophet.make_future_dataframe() got multiple values for argument 'periods'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model_temp\u001b[38;5;241m.\u001b[39mfit(prophet_df)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make predictions for the future (test set)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m future_temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_temp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_future_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprophet_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 'D' for daily frequency\u001b[39;00m\n\u001b[0;32m     20\u001b[0m forecast_temp \u001b[38;5;241m=\u001b[39m model_temp\u001b[38;5;241m.\u001b[39mpredict(future_temp)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# View the forecast\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Prophet.make_future_dataframe() got multiple values for argument 'periods'"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Create the 'ds' column for the Prophet model (using Year, Month, Day)\n",
    "full_df['ds'] = pd.to_datetime(full_df['Year'].astype(str) + '-' + full_df['Month'].astype(str) + '-' + full_df['Day'].astype(str))\n",
    "\n",
    "# Prepare data for Prophet for each target variable\n",
    "\n",
    "# For example, predicting Avg_Temperature\n",
    "prophet_df = full_df[['ds', 'Avg_Temperature']].dropna()\n",
    "\n",
    "# Rename columns for Prophet\n",
    "prophet_df.columns = ['ds', 'y']\n",
    "\n",
    "# Initialize and fit the Prophet model\n",
    "model_temp = Prophet()\n",
    "model_temp.fit(prophet_df)\n",
    "\n",
    "# Make predictions for the future (test set)\n",
    "future_temp = model_temp.make_future_dataframe(prophet_df, periods=len(test_df), freq='D')  # 'D' for daily frequency\n",
    "forecast_temp = model_temp.predict(future_temp)\n",
    "\n",
    "# View the forecast\n",
    "forecast_temp[['ds', 'yhat']].tail()\n",
    "\n",
    "# For Radiation\n",
    "prophet_df_radiation = full_df[['ds', 'Radiation']].dropna()\n",
    "prophet_df_radiation.columns = ['ds', 'y']\n",
    "model_radiation = Prophet()\n",
    "model_radiation.fit(prophet_df_radiation)\n",
    "future_radiation = model_radiation.make_future_dataframe(prophet_df_radiation, periods=len(test_df), freq='D')\n",
    "forecast_radiation = model_radiation.predict(future_radiation)\n",
    "\n",
    "# For Rain_Amount\n",
    "prophet_df_rain = full_df[['ds', 'Rain_Amount']].dropna()\n",
    "prophet_df_rain.columns = ['ds', 'y']\n",
    "model_rain = Prophet()\n",
    "model_rain.fit(prophet_df_rain)\n",
    "future_rain = model_rain.make_future_dataframe(prophet_df_rain, periods=len(test_df), freq='D')\n",
    "forecast_rain = model_rain.predict(future_rain)\n",
    "\n",
    "# For Wind_Speed\n",
    "prophet_df_wind_speed = full_df[['ds', 'Wind_Speed']].dropna()\n",
    "prophet_df_wind_speed.columns = ['ds', 'y']\n",
    "model_wind_speed = Prophet()\n",
    "model_wind_speed.fit(prophet_df_wind_speed)\n",
    "future_wind_speed = model_wind_speed.make_future_dataframe(prophet_df_wind_speed, periods=len(test_df), freq='D')\n",
    "forecast_wind_speed = model_wind_speed.predict(future_wind_speed)\n",
    "\n",
    "# For Wind_Direction\n",
    "prophet_df_wind_direction = full_df[['ds', 'Wind_Direction']].dropna()\n",
    "prophet_df_wind_direction.columns = ['ds', 'y']\n",
    "model_wind_direction = Prophet()\n",
    "model_wind_direction.fit(prophet_df_wind_direction)\n",
    "future_wind_direction = model_wind_direction.make_future_dataframe(prophet_df_wind_direction, periods=len(test_df), freq='D')\n",
    "forecast_wind_direction = model_wind_direction.predict(future_wind_direction)\n",
    "\n",
    "# Combine predictions with the 'ID' from the test set\n",
    "predictions = test_df[['ID']].copy()\n",
    "predictions['Avg_Temperature'] = forecast_temp['yhat'][-len(test_df):].values\n",
    "predictions['Radiation'] = forecast_radiation['yhat'][-len(test_df):].values\n",
    "predictions['Rain_Amount'] = forecast_rain['yhat'][-len(test_df):].values\n",
    "predictions['Wind_Speed'] = forecast_wind_speed['yhat'][-len(test_df):].values\n",
    "predictions['Wind_Direction'] = forecast_wind_direction['yhat'][-len(test_df):].values\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions.to_csv('prophet_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
