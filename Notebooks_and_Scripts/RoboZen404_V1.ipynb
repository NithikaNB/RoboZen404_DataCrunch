{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'E:\\NB\\Machine Learning\\UOM - DataCrunch\\RoboZen404_DataCrunch\\dataset\\train.csv') #replace with your file name.\n",
    "test_df = pd.read_csv(r'E:\\NB\\Machine Learning\\UOM - DataCrunch\\RoboZen404_DataCrunch\\dataset\\test.csv')\n",
    "\n",
    "# Load your train and test datasets\n",
    "train_df['is_test'] = 0  # Mark training data\n",
    "test_df['is_test'] = 1   # Mark test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84960, 18)\n",
      "   ID  Year  Month  Day   kingdom   latitude  longitude  Avg_Temperature  \\\n",
      "0   1     1      4    1   Arcadia  24.280002 -37.229980            25.50   \n",
      "1   2     1      4    1  Atlantis  22.979999 -37.329990           299.65   \n",
      "2   3     1      4    1    Avalon  22.880000 -37.130006            26.30   \n",
      "3   4     1      4    1   Camelot  24.180003 -36.929994            24.00   \n",
      "4   5     1      4    1     Dorne  25.780002 -37.530000            28.00   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                       30.50                8.5   \n",
      "1                      305.15                5.9   \n",
      "2                       31.50                5.2   \n",
      "3                       28.40                8.2   \n",
      "4                       32.80                5.7   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                          10.3      22.52        58.89             16   \n",
      "1                           8.2      22.73        11.83             12   \n",
      "2                           6.4      22.73        11.83             12   \n",
      "3                          10.7      22.67        75.27             16   \n",
      "4                          10.2      22.35         4.81              8   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  is_test  \n",
      "0         8.6             283            1.648659        0  \n",
      "1        15.8             161            1.583094        0  \n",
      "2        15.8             161            1.593309        0  \n",
      "3         6.4             346            1.638997        0  \n",
      "4        16.7             185            1.719189        0  \n",
      "(4530, 18)\n",
      "      ID  Year  Month  Day   kingdom  is_test  latitude  longitude  \\\n",
      "0  84961     9      1    1   Arcadia        1       NaN        NaN   \n",
      "1  84962     9      1    1  Atlantis        1       NaN        NaN   \n",
      "2  84963     9      1    1    Avalon        1       NaN        NaN   \n",
      "3  84964     9      1    1   Camelot        1       NaN        NaN   \n",
      "4  84965     9      1    1     Dorne        1       NaN        NaN   \n",
      "\n",
      "   Avg_Temperature  Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0              NaN                         NaN                NaN   \n",
      "1              NaN                         NaN                NaN   \n",
      "2              NaN                         NaN                NaN   \n",
      "3              NaN                         NaN                NaN   \n",
      "4              NaN                         NaN                NaN   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                           NaN        NaN          NaN            NaN   \n",
      "1                           NaN        NaN          NaN            NaN   \n",
      "2                           NaN        NaN          NaN            NaN   \n",
      "3                           NaN        NaN          NaN            NaN   \n",
      "4                           NaN        NaN          NaN            NaN   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  \n",
      "0         NaN             NaN                 NaN  \n",
      "1         NaN             NaN                 NaN  \n",
      "2         NaN             NaN                 NaN  \n",
      "3         NaN             NaN                 NaN  \n",
      "4         NaN             NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# List of missing columns in test data\n",
    "missing_cols = ['latitude', 'longitude', 'Avg_Temperature', 'Avg_Feels_Like_Temperature', \n",
    "                'Temperature_Range', 'Feels_Like_Temperature_Range', 'Radiation', \n",
    "                'Rain_Amount', 'Rain_Duration', 'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']\n",
    "\n",
    "# Add them with NaN values in test data\n",
    "for col in missing_cols:\n",
    "    test_df[col] = np.nan\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                              0\n",
      "Year                            0\n",
      "Month                           0\n",
      "Day                             0\n",
      "kingdom                         0\n",
      "latitude                        0\n",
      "longitude                       0\n",
      "Avg_Temperature                 0\n",
      "Avg_Feels_Like_Temperature      0\n",
      "Temperature_Range               0\n",
      "Feels_Like_Temperature_Range    0\n",
      "Radiation                       0\n",
      "Rain_Amount                     0\n",
      "Rain_Duration                   0\n",
      "Wind_Speed                      0\n",
      "Wind_Direction                  0\n",
      "Evapotranspiration              0\n",
      "is_test                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no any missing values in the train dataset. So we can concatinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data\n",
    "full_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID      latitude     longitude  Avg_Temperature  \\\n",
      "count  8.949000e+04  8.496000e+04  8.496000e+04     8.496000e+04   \n",
      "mean  -6.097853e-17  1.784992e-15 -1.646687e-14    -9.697202e-17   \n",
      "std    1.000006e+00  1.000006e+00  1.000006e+00     1.000006e+00   \n",
      "min   -1.732031e+00 -1.406599e+00 -9.477272e-01    -8.754289e-01   \n",
      "25%   -8.660157e-01 -4.048639e-01 -7.432270e-01    -8.178156e-01   \n",
      "50%    0.000000e+00 -2.796493e-01 -5.386612e-01    -8.043475e-01   \n",
      "75%    8.660157e-01  3.464329e-01  2.795403e-01     1.225213e+00   \n",
      "max    1.732031e+00  3.226416e+00  3.143342e+00     1.257387e+00   \n",
      "\n",
      "       Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "count                8.496000e+04       8.496000e+04   \n",
      "mean                -8.346535e-17       1.552221e-16   \n",
      "std                  1.000006e+00       1.000006e+00   \n",
      "min                 -9.036781e-01      -2.449927e+00   \n",
      "25%                 -8.170698e-01      -7.813450e-01   \n",
      "50%                 -8.006441e-01      -1.240248e-01   \n",
      "75%                  1.225318e+00       5.838585e-01   \n",
      "max                  1.268622e+00       5.083974e+00   \n",
      "\n",
      "       Feels_Like_Temperature_Range     Radiation   Rain_Amount  \\\n",
      "count                  8.496000e+04  8.496000e+04  8.496000e+04   \n",
      "mean                   9.634478e-17  1.102612e-15 -5.419394e-17   \n",
      "std                    1.000006e+00  1.000006e+00  1.000006e+00   \n",
      "min                   -2.344662e+00 -4.163379e+00 -5.731089e-01   \n",
      "25%                   -7.847088e-01 -5.507758e-01 -5.345250e-01   \n",
      "50%                   -6.797353e-02  1.508656e-01 -3.223132e-01   \n",
      "75%                    6.909227e-01  7.189766e-01  1.310482e-01   \n",
      "max                    4.611886e+00  2.369897e+00  3.210750e+01   \n",
      "\n",
      "       Rain_Duration    Wind_Speed  Wind_Direction  Evapotranspiration  \n",
      "count   8.496000e+04  8.496000e+04    8.496000e+04        8.496000e+04  \n",
      "mean    9.366853e-17 -1.926896e-16    1.204310e-17        1.578984e-16  \n",
      "std     1.000006e+00  1.000006e+00    1.000006e+00        1.000006e+00  \n",
      "min    -1.230131e+00 -2.150328e+00   -2.298099e+00       -5.200972e+00  \n",
      "25%    -9.535631e-01 -7.306813e-01   -1.031027e+00       -5.326730e-01  \n",
      "50%    -1.238584e-01 -8.538717e-02    4.170552e-01        9.329300e-02  \n",
      "75%     8.441305e-01  5.437746e-01    7.471328e-01        6.680502e-01  \n",
      "max     2.088688e+00  5.577069e+00    1.524412e+00        2.928921e+00  \n"
     ]
    }
   ],
   "source": [
    "# Separate out date-related columns (Year, Month, Day) from numerical columns\n",
    "date_cols = ['Year', 'Month', 'Day', 'is_test']  # Adjust based on your dataset\n",
    "\n",
    "# Get only numerical columns that are not date-related\n",
    "numerical_cols = [col for col in full_df.select_dtypes(include=np.number).columns if col not in date_cols]\n",
    "\n",
    "# Apply StandardScaler or MinMaxScaler only to the numerical columns\n",
    "scaler = StandardScaler()\n",
    "full_df[numerical_cols] = scaler.fit_transform(full_df[numerical_cols])\n",
    "\n",
    "# Alternatively, use MinMaxScaler if preferred\n",
    "# scaler = MinMaxScaler()\n",
    "# full_df[numerical_cols] = scaler.fit_transform(full_df[numerical_cols])\n",
    "\n",
    "# Check the results to confirm scaling\n",
    "print(full_df[numerical_cols].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3  # Adjust based on need\n",
    "\n",
    "smooth_features = ['Avg_Temperature', 'Avg_Feels_Like_Temperature', \n",
    "                   'Temperature_Range', 'Feels_Like_Temperature_Range',\n",
    "                   'Radiation', 'Evapotranspiration']\n",
    "\n",
    "for feature in smooth_features:\n",
    "    full_df[feature] = full_df[feature].rolling(window=window_size, min_periods=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3  # Smoothing factor (0 < alpha < 1)\n",
    "\n",
    "for feature in smooth_features:\n",
    "    full_df[feature] = full_df[feature].ewm(alpha=alpha, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0 -1.732031     1      4    1   Arcadia  0.346433   0.075040        -0.823801   \n",
      "1 -1.731993     1      4    1  Atlantis -1.281385  -0.129534        -0.516113   \n",
      "2 -1.731954     1      4    1    Avalon -1.406599   0.279540        -0.402695   \n",
      "3 -1.731915     1      4    1   Camelot  0.221218   0.688672        -0.324425   \n",
      "4 -1.731877     1      4    1     Dorne  2.224680  -0.538661        -0.472891   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                   -0.815577           1.595120   \n",
      "1                   -0.507987           1.397924   \n",
      "2                   -0.394457           1.158761   \n",
      "3                   -0.316554           0.976178   \n",
      "4                   -0.465365           0.838257   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                      1.660623   0.529606     3.796523       0.982415   \n",
      "1                      1.527817   0.537254     0.304676       0.429278   \n",
      "2                      1.314693   0.545156     0.304676       0.429278   \n",
      "3                      1.182371   0.554330     5.011918       0.982415   \n",
      "4                      1.174068   0.551526    -0.216207      -0.123858   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  is_test  \n",
      "0   -1.133990        0.715190            0.363578        0  \n",
      "1    0.027539       -0.583825            0.318846        0  \n",
      "2    0.027539       -0.583825            0.277268        0  \n",
      "3   -1.488902        1.385993            0.243769        0  \n",
      "4    0.172730       -0.328281            0.282221        0  \n"
     ]
    }
   ],
   "source": [
    "# Check first few rows of full_df\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split full_df into train and test\n",
    "train_df = full_df[full_df['is_test'] == 0].drop(columns=['is_test'])\n",
    "test_df = full_df[full_df['is_test'] == 1].drop(columns=['is_test', 'Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction'])\n",
    "\n",
    "\n",
    "scaled_features = ['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range',\n",
    "                   'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount', 'Rain_Duration',\n",
    "                   'Wind_Speed', 'Evapotranspiration']\n",
    "\n",
    "\n",
    "scaled_features = [feature for feature in scaled_features if feature in full_df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84960, 17)\n",
      "         ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0 -1.732031     1      4    1   Arcadia  0.346433   0.075040        -0.823801   \n",
      "1 -1.731993     1      4    1  Atlantis -1.281385  -0.129534        -0.516113   \n",
      "2 -1.731954     1      4    1    Avalon -1.406599   0.279540        -0.402695   \n",
      "3 -1.731915     1      4    1   Camelot  0.221218   0.688672        -0.324425   \n",
      "4 -1.731877     1      4    1     Dorne  2.224680  -0.538661        -0.472891   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                   -0.815577           1.595120   \n",
      "1                   -0.507987           1.397924   \n",
      "2                   -0.394457           1.158761   \n",
      "3                   -0.316554           0.976178   \n",
      "4                   -0.465365           0.838257   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                      1.660623   0.529606     3.796523       0.982415   \n",
      "1                      1.527817   0.537254     0.304676       0.429278   \n",
      "2                      1.314693   0.545156     0.304676       0.429278   \n",
      "3                      1.182371   0.554330     5.011918       0.982415   \n",
      "4                      1.174068   0.551526    -0.216207      -0.123858   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  \n",
      "0   -1.133990        0.715190            0.363578  \n",
      "1    0.027539       -0.583825            0.318846  \n",
      "2    0.027539       -0.583825            0.277268  \n",
      "3   -1.488902        1.385993            0.243769  \n",
      "4    0.172730       -0.328281            0.282221  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after outlier removal: (0, 18)\n"
     ]
    }
   ],
   "source": [
    "z_threshold = 3  # Common threshold (|Z-score| > 3 is considered an outlier)\n",
    "full_df = full_df[(np.abs(zscore(full_df[scaled_features])) < z_threshold).all(axis=1)]\n",
    "\n",
    "print(\"Dataset shape after outlier removal:\", full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape after concatenation: (89490, 18)\n",
      "         ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0 -1.732031     1      4    1   Arcadia  0.346433   0.075040        -0.823801   \n",
      "1 -1.731993     1      4    1  Atlantis -1.281385  -0.129534        -0.516113   \n",
      "2 -1.731954     1      4    1    Avalon -1.406599   0.279540        -0.402695   \n",
      "3 -1.731915     1      4    1   Camelot  0.221218   0.688672        -0.324425   \n",
      "4 -1.731877     1      4    1     Dorne  2.224680  -0.538661        -0.472891   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                   -0.815577           1.595120   \n",
      "1                   -0.507987           1.397924   \n",
      "2                   -0.394457           1.158761   \n",
      "3                   -0.316554           0.976178   \n",
      "4                   -0.465365           0.838257   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                      1.660623   0.529606     3.796523       0.982415   \n",
      "1                      1.527817   0.537254     0.304676       0.429278   \n",
      "2                      1.314693   0.545156     0.304676       0.429278   \n",
      "3                      1.182371   0.554330     5.011918       0.982415   \n",
      "4                      1.174068   0.551526    -0.216207      -0.123858   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration  is_test  \n",
      "0   -1.133990        0.715190            0.363578        0  \n",
      "1    0.027539       -0.583825            0.318846        0  \n",
      "2    0.027539       -0.583825            0.277268        0  \n",
      "3   -1.488902        1.385993            0.243769        0  \n",
      "4    0.172730       -0.328281            0.282221        0  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Concatenate the cleaned train_df and the test_df back into full_df\n",
    "# We add the 'is_test' column again for clarity, if you need it later\n",
    "train_df['is_test'] = 0  # Mark the train data\n",
    "test_df['is_test'] = 1   # Mark the test data\n",
    "\n",
    "# Concatenate train and test data back into full_df\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Step 3: Check the shape and preview of the concatenated data\n",
    "print(\"Full dataset shape after concatenation:\", full_df.shape)\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lag Features: We created lag features to capture temporal dependencies without relying on actual time. These included shifts of key variables like temperature, wind speed, and rain amount (e.g., 1-day lag).\n",
    "\n",
    "Rolling Features: We introduced rolling statistics, such as moving averages and rolling sums, to identify trends over a specified window (e.g., 7-day moving averages for temperature and rain).\n",
    "\n",
    "Seasonal Features: To account for cycles, we grouped the data into hypothetical seasons based on the \"Year\" variable, using a modulo operation to classify records into 4 seasons.\n",
    "\n",
    "Aggregated Features by Kingdom: We aggregated key variables like temperature and wind speed by \"kingdom\" to capture regional patterns and trends.\n",
    "\n",
    "External Variables: We considered adding external features like radiation levels or indicators based on thresholds (e.g., high radiation) to help the model capture important weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a lag of 1 day for 'Avg_Temperature'\n",
    "full_df['Avg_Temperature_Lag_1'] = full_df['Avg_Temperature'].shift(1)\n",
    "full_df['Wind_Speed_Lag_1'] = full_df['Wind_Speed'].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Avg_Temperature_Lag_2'] = full_df['Avg_Temperature'].shift(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average over 7 days for 'Avg_Temperature'\n",
    "full_df['Avg_Temperature_MA_7'] = full_df['Avg_Temperature'].rolling(window=7).mean()\n",
    "full_df['Rain_Amount_MA_7'] = full_df['Rain_Amount'].rolling(window=7).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling sum over 7 days\n",
    "full_df['Rain_Amount_Rolling_Sum_7'] = full_df['Rain_Amount'].rolling(window=7).sum()\n",
    "\n",
    "# Rolling standard deviation\n",
    "full_df['Wind_Speed_Rolling_Std_7'] = full_df['Wind_Speed'].rolling(window=7).std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal Features (Non-time-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Season'] = (full_df['Year'] % 4)  # Group into 4 seasons based on the hypothetical year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregated Features by Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Avg_Temperature_Kingdom_Mean'] = full_df.groupby('kingdom')['Avg_Temperature'].transform('mean')\n",
    "full_df['Wind_Speed_Kingdom_Mean'] = full_df.groupby('kingdom')['Wind_Speed'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['High_Radiation'] = (full_df['Radiation'] > full_df['Radiation'].median()).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "#result = adfuller(full_df['Avg_Temperature'])\n",
    "#print(f'ADF Statistic: {result[0]}')\n",
    "#print(f'p-value: {result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above values have tested ans since the ADF statistic is -31.50 and the p-value is 0.0, this means that the data is stationary. No need to do any transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SPLIT BACK INTO TRAIN AND TEST --- ###\n",
    "train_df = full_df[full_df['is_test'] == 0].drop(columns=['is_test'])\n",
    "test_df = full_df[full_df['is_test'] == 1].drop(columns=['is_test', 'Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84960, 28)\n",
      "         ID  Year  Month  Day   kingdom  latitude  longitude  Avg_Temperature  \\\n",
      "0 -1.732031     1      4    1   Arcadia  0.346433   0.075040        -0.823801   \n",
      "1 -1.731993     1      4    1  Atlantis -1.281385  -0.129534        -0.516113   \n",
      "2 -1.731954     1      4    1    Avalon -1.406599   0.279540        -0.402695   \n",
      "3 -1.731915     1      4    1   Camelot  0.221218   0.688672        -0.324425   \n",
      "4 -1.731877     1      4    1     Dorne  2.224680  -0.538661        -0.472891   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  ...  Wind_Speed_Lag_1  \\\n",
      "0                   -0.815577           1.595120  ...               NaN   \n",
      "1                   -0.507987           1.397924  ...         -1.133990   \n",
      "2                   -0.394457           1.158761  ...          0.027539   \n",
      "3                   -0.316554           0.976178  ...          0.027539   \n",
      "4                   -0.465365           0.838257  ...         -1.488902   \n",
      "\n",
      "   Avg_Temperature_Lag_2  Avg_Temperature_MA_7  Rain_Amount_MA_7  \\\n",
      "0                    NaN                   NaN               NaN   \n",
      "1                    NaN                   NaN               NaN   \n",
      "2              -0.823801                   NaN               NaN   \n",
      "3              -0.516113                   NaN               NaN   \n",
      "4              -0.402695                   NaN               NaN   \n",
      "\n",
      "   Rain_Amount_Rolling_Sum_7  Wind_Speed_Rolling_Std_7  Season  \\\n",
      "0                        NaN                       NaN       1   \n",
      "1                        NaN                       NaN       1   \n",
      "2                        NaN                       NaN       1   \n",
      "3                        NaN                       NaN       1   \n",
      "4                        NaN                       NaN       1   \n",
      "\n",
      "   Avg_Temperature_Kingdom_Mean  Wind_Speed_Kingdom_Mean  High_Radiation  \n",
      "0                     -0.239763                -0.119008               1  \n",
      "1                     -0.210497                 0.362269               1  \n",
      "2                     -0.187895                 0.362269               1  \n",
      "3                     -0.173608                -0.612907               1  \n",
      "4                     -0.367731                 1.383227               1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "\n",
    "# print(test_df.shape)\n",
    "# print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
